{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZLpEp5z9X7Wd"
      ],
      "authorship_tag": "ABX9TyOHg14w8GxyNWvginXv4btZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrisMatrix/TensorFlow_Certification_Prep/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYUUXjgaTKzQ"
      },
      "source": [
        "# Introduction to NLP fundamentals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequence text or speech). \n",
        "\n",
        "Another common term for NLP problems is sequence to sequence (seq2seq) problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqZ3M80NTtho"
      },
      "source": [
        "# Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzkPQYEFTvqT",
        "outputId": "ee15ee7e-a4c0-48d5-b132-da8d8f62e148"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-5c1e75e3-f81c-b059-1307-01d239deefa4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eIQGWiDTxEj",
        "outputId": "6737b8f6-b1bc-418d-fc2f-25f81d97b6f0"
      },
      "source": [
        "# Get helper functions\n",
        "\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-11 17:34:33--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-11 17:34:33 (46.5 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58LWG-iaULDW"
      },
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdvmf1JeUVo-"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's intro to NLP dataset (text samples of Tweets labelled as disaster or not disaster).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DISD0BwUZm-",
        "outputId": "5dae4c4b-03bf-4a6e-8a58-2f018f76f3d7"
      },
      "source": [
        "! wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-11 17:34:35--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.191.128, 173.194.192.128, 209.85.147.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.191.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip.1’\n",
            "\n",
            "\r          nlp_getti   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-09-11 17:34:35 (94.8 MB/s) - ‘nlp_getting_started.zip.1’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T67j434bUvum"
      },
      "source": [
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TibhVQOvU0_G"
      },
      "source": [
        "## Visualizing a text dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OsgpbZ4VLyG"
      },
      "source": [
        "To visualize our text samples, we first have to read them in, one way to so would be to use Python.\n",
        "\n",
        "But I prefer to get visual straight away ...\n",
        "\n",
        "So another way to do this is to use pandas..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1gq_4PDPVuZi",
        "outputId": "70eb993c-fcb9-41cc-da5c-47e05cffc7ab"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u_VN9M0aV4xf",
        "outputId": "0b2a7259-119d-47d3-9bd0-c26ba7fa62fb"
      },
      "source": [
        "train_df['text'][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DlWsSpuxV7-7",
        "outputId": "96388dc5-9e27-4863-b1b6-e98adc959e6f"
      },
      "source": [
        "#Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TezaPwBJWQUY",
        "outputId": "de0d7916-26c8-4eea-fb70-3353711a5712"
      },
      "source": [
        "# What does the test dataframe look like\n",
        "test_df.head()  #just doesn't have target."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eve-rj-bWarV",
        "outputId": "7bf2f609-8f9d-4947-ef54-34cb9aab7a43"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm7VGingWjsF",
        "outputId": "52cbe07d-6df8-4849-d5ef-f9ad09cfacf9"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdgdg3GPW-gm",
        "outputId": "176f6102-7612-4858-df53-f63720e60f6d"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5)  #create random indexes\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "https://t.co/oIfN28HpCS @ArianaGrande @ScreamQueens \n",
            "Katherine's death\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Uribe demolished that ball ??????\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "A tornado flew around my room before you came\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "New Nanotech Device Will Be Able To Target And Destroy Blood Clots http://t.co/HFy5V3sLBB\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Floods Fishing Finally Sunshine &amp; Fab Deals from Albertsons Anniversary Sale |Lauren Paints | a beautiful life http://t.co/CwHSLMB8x9\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLpEp5z9X7Wd"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IIaiRBoZIda"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYkcePj1ZNq1"
      },
      "source": [
        "#Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                           train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                           test_size=0.1, #use 10% of training data for valid\n",
        "                                                                           random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfK7Ww2fZvhp",
        "outputId": "6c904235-8388-4cff-d215-e584980ae4ac"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2bm6Bl9aC7V",
        "outputId": "5a710e62-537d-40a7-92b1-a9bd0001dd97"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3FWQBEyaOPz"
      },
      "source": [
        "## Converting text into numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbJZz501afRB"
      },
      "source": [
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenization - direct mapping of token (a token could be a word or a character) to a number.\n",
        "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZy87jfehegr"
      },
      "source": [
        "## Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rnlq1ZbhiGx",
        "outputId": "3c824112-78f1-4eb6-d11e-eade0df10d7a"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoG8fhlghkWY"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
        "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
        "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfHSPB5vnJkn",
        "outputId": "3abf3979-95cf-4068-d2b9-5af8f5e1c973"
      },
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa6boJAGn30x"
      },
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b54wSJpln63U"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52WGgr1Pn8vy",
        "outputId": "57482080-95a4-452d-c36a-84d00192ddd3"
      },
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZssYv9qKn-to",
        "outputId": "9077bcb4-e842-48b3-eb3d-f526daa8c389"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "70 years ago today the U.S.  dropped a nuclear weapon on Japan. Here are some articles that share my opinion on that decisionÛ_      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 325,  141,  750,  124,    2,   69, 1870,    3,  105,  263,   11,\n",
              "         224,  140,   22,   82]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIHdiyYNoAyg",
        "outputId": "2a128b02-3d7e-441e-bd6e-e21af16fc76d"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndGRD3vWoCzR"
      },
      "source": [
        "## Creating an Embedding Layer\n",
        "\n",
        "To make our embedding, we're going to use TensorFlow's embedding layer.\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip_2acTw08Ba",
        "outputId": "406e8522-afa0-4e89-d44f-cf15c5e1443e"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length) # how long is each input\n",
        "\n",
        "embedding"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f6c203454d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLbCJXT1089Q",
        "outputId": "aa6a24c7-415b-451f-fc4e-c62f0f3ce7ce"
      },
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Las Vegas in top 5 cities for red-light running fatalities - News3LV http://t.co/eXdbcx4gCR      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.01319343,  0.00094383,  0.03795994, ...,  0.0348247 ,\n",
              "          0.003139  , -0.03008923],\n",
              "        [-0.015508  ,  0.01783958,  0.00797755, ...,  0.03018178,\n",
              "          0.01310921, -0.00636036],\n",
              "        [-0.01723858, -0.01769469,  0.01752433, ..., -0.01777048,\n",
              "         -0.03914837, -0.0111191 ],\n",
              "        ...,\n",
              "        [-0.0202919 , -0.03337848,  0.03656572, ..., -0.00867773,\n",
              "          0.03417848,  0.03655838],\n",
              "        [-0.0202919 , -0.03337848,  0.03656572, ..., -0.00867773,\n",
              "          0.03417848,  0.03655838],\n",
              "        [-0.0202919 , -0.03337848,  0.03656572, ..., -0.00867773,\n",
              "          0.03417848,  0.03655838]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dFB2oCX0--U",
        "outputId": "f6b7d4f6-a7fe-462d-a5c9-f117a724c36b"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 0.01319343,  0.00094383,  0.03795994, -0.00682693,  0.03922417,\n",
              "        0.02209156, -0.02235245,  0.03079636,  0.03805442,  0.03211553,\n",
              "       -0.00625305, -0.04542823, -0.03305288,  0.03407397,  0.02714917,\n",
              "       -0.01938601,  0.01698897, -0.02193478, -0.00515227,  0.03680152,\n",
              "        0.02340115,  0.04924435,  0.01430732, -0.02573018, -0.00312651,\n",
              "       -0.03534408,  0.04656405, -0.04553846, -0.02690182,  0.0158175 ,\n",
              "       -0.04511812, -0.03867165,  0.04522375,  0.00208383, -0.01586616,\n",
              "       -0.0380797 , -0.04658697, -0.0204453 , -0.04962256, -0.03824158,\n",
              "        0.04544501,  0.01524505,  0.0261708 , -0.03647786,  0.03732483,\n",
              "        0.03021472,  0.03670395,  0.03044648,  0.00889864, -0.0243018 ,\n",
              "        0.00508133, -0.02943964,  0.03010743,  0.04013881,  0.02529824,\n",
              "       -0.03436098,  0.01342917,  0.00697602, -0.00233121, -0.04524968,\n",
              "        0.00116141,  0.00519135, -0.04829584, -0.0207068 ,  0.03617162,\n",
              "       -0.00843315, -0.04657022,  0.01616284,  0.02577646,  0.02750677,\n",
              "       -0.03401639, -0.04985782,  0.02402711,  0.02508989, -0.04610458,\n",
              "       -0.0459826 , -0.02825003,  0.026184  , -0.04764165, -0.03159295,\n",
              "       -0.01232265,  0.04718417,  0.00377256, -0.04717227, -0.02874876,\n",
              "       -0.01939486,  0.0238216 , -0.01682794,  0.03021662,  0.00014386,\n",
              "       -0.01438029,  0.03223057,  0.01202667,  0.04823222,  0.00230659,\n",
              "       -0.0245815 ,  0.02898438, -0.01920908,  0.00912189,  0.04477391,\n",
              "       -0.01303774, -0.01204072, -0.00547301,  0.02760501, -0.01560188,\n",
              "        0.04561805, -0.00777704,  0.04241553,  0.0043714 ,  0.02200575,\n",
              "        0.04950609,  0.01050854, -0.02185865,  0.0184742 ,  0.03059149,\n",
              "        0.00866743, -0.00089141,  0.04526098,  0.0242149 , -0.00830495,\n",
              "        0.0494179 ,  0.00309601, -0.03956804, -0.00329256,  0.03955135,\n",
              "        0.0348247 ,  0.003139  , -0.03008923], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soJ4BIr31BfL"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "* **Model 0:** Naive Bayes (baseline)\n",
        "* **Model 1:** Feed-forward neural network (dense model)\n",
        "* **Model 2:** LSTM model\n",
        "* **Model 3:** GRU model\n",
        "* **Model 4:** Bidirectional-LSTM model\n",
        "* **Model 5:** 1D Convolutional Neural Network\n",
        "* **Model 6:** TensorFlow Hub Pretrained Feature Extractor\n",
        "* **Model 7:** Same as model 6 with 10% of training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtGr6JR03aBU"
      },
      "source": [
        "### Model 0: Getting a baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydF4d7q039Px",
        "outputId": "72ca404c-375a-4d6c-a4b8-a644491e0e83"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi_xFHnR3_IU",
        "outputId": "f91d5ae7-8365-4346-84f9-f15ff7701619"
      },
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNaBIPyw4BBH",
        "outputId": "70cc50ed-dfb4-4329-da4b-c0748fe1da37"
      },
      "source": [
        "\n",
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pr2a4Z94CWQ"
      },
      "source": [
        "### Creating an evaluation function for our model experiements\n",
        "\n",
        "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "\n",
        "**Note:** Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbKjCC-64NgH"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTS4FOPd4PFj",
        "outputId": "b77ee40e-76a9-4bca-b2b2-2a97b03aa070"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISkwdJl74QUq"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-dqCrSv4WSV"
      },
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoPRA9NV4YVt"
      },
      "source": [
        "\n",
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN9waO-u4ZYD"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwAuI6kR4a4e",
        "outputId": "10472453-8569-48fe-ac5a-40ce4a4a84ca"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_1.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie-QCdrV4cCQ",
        "outputId": "7c15bfdf-0478-4358-c8ca-8eaddba3682b"
      },
      "source": [
        "\n",
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20210911-173438\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 10ms/step - loss: 0.6127 - accuracy: 0.6929 - val_loss: 0.5360 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.4429 - accuracy: 0.8186 - val_loss: 0.4690 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.3477 - accuracy: 0.8637 - val_loss: 0.4588 - val_accuracy: 0.7966\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.2850 - accuracy: 0.8898 - val_loss: 0.4647 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.2385 - accuracy: 0.9111 - val_loss: 0.4773 - val_accuracy: 0.7848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IpxsRly4eRs",
        "outputId": "f9c015fe-d499-42ba-b872-4cdad974cf43"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47732415795326233, 0.7847769260406494]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kai54t2V4gXn",
        "outputId": "aadae4c3-1798-437b-af5c-9bee69c790d5"
      },
      "source": [
        "# Make predictions (these come back in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35021704],\n",
              "       [0.7982371 ],\n",
              "       [0.9979443 ],\n",
              "       [0.13098286],\n",
              "       [0.13528593],\n",
              "       [0.94345367],\n",
              "       [0.9232751 ],\n",
              "       [0.9933756 ],\n",
              "       [0.96714926],\n",
              "       [0.299709  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C-wP6fb4lLP",
        "outputId": "2dbdf43a-f16b-4106-fcf0-08ac5ba3fcae"
      },
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqGJMvPE4m1D",
        "outputId": "dc717914-921d-432f-e30b-885bb24cbbf2"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.4776902887139,\n",
              " 'f1': 0.7818959205825942,\n",
              " 'precision': 0.789165199286798,\n",
              " 'recall': 0.7847769028871391}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiet9rig4pBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fb413e-79e3-4bcc-a7d0-e6f1f4652190"
      },
      "source": [
        "# Is our simple Keras model better than our baseline model?\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHl8xSL44rsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb0276a-dc75-4923-e41b-e02772f01e90"
      },
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
        "                                new_model_results=model_1_results)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.48, Difference: -0.79\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLciGaV04s96"
      },
      "source": [
        "### Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premise of a RNN is to use the representation of a previous input to aid the representation of a later input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8g81hJkVnF"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = Long Short Term Memory (one of the most popular RNNs)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrTSaI4fkq1_",
        "outputId": "1c9e2a79-d2ec-4e8b-c6d2-f72ef7720d8e"
      },
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 64)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T9UEI6ulWfi",
        "outputId": "2beae8be-4540-4e1e-928a-0b10e0b75b35"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 15, 64)            49408     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,366,657\n",
            "Trainable params: 1,366,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQePfirnnOhi"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OX_capfnbJ6",
        "outputId": "36358ee5-d5e6-4ec6-f1a3-739e68831c0f"
      },
      "source": [
        "#$ Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_2_LSTM\")])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210911-173449\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 23ms/step - loss: 0.2240 - accuracy: 0.9253 - val_loss: 0.6563 - val_accuracy: 0.7756\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1564 - accuracy: 0.9407 - val_loss: 0.6144 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.1341 - accuracy: 0.9470 - val_loss: 0.7438 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1071 - accuracy: 0.9600 - val_loss: 0.7783 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0861 - accuracy: 0.9642 - val_loss: 0.8782 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uetgK7pRntWO",
        "outputId": "04823a8f-f7f1-4938-d8b5-539b757c6353"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9339634e-02],\n",
              "       [9.2917091e-01],\n",
              "       [9.9997211e-01],\n",
              "       [9.8332778e-02],\n",
              "       [2.6101753e-04],\n",
              "       [9.9942845e-01],\n",
              "       [9.3365002e-01],\n",
              "       [9.9998045e-01],\n",
              "       [9.9996173e-01],\n",
              "       [4.4676340e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU4tqUuvn26b",
        "outputId": "1a1c1d02-7c7b-49af-d6d0-8de358955fbf"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGRLXLrzoC1L",
        "outputId": "ddab418c-f3ba-416f-9ec9-fe65c7b9bd4c"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.7680604812955161,\n",
              " 'precision': 0.7723473976820748,\n",
              " 'recall': 0.7703412073490814}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz7F8ZHXoQS9",
        "outputId": "dfb9cc5a-7682-4114-9f07-17807a4915a0"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ppuGrGcoT6t"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU (gated recurrent unit).\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6dP5MffqH9o",
        "outputId": "98569f19-c79c-417f-ec95-0b3d6e9e690f"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.GRU(64, return_sequences=True)(x) #if you want to stack recurrent layers \n",
        "print(x.shape)\n",
        "x = layers.LSTM(42, return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "x = layers.GRU(99, return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 15, 42)\n",
            "(None, 15, 99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdqxr2y4r4Pc",
        "outputId": "512a7108-d15c-4ed7-915e-c5a4e69b29ab"
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 15, 64)            37248     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 15, 42)            17976     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 15, 99)            42471     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15, 64)            6400      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 15, 1)             65        \n",
            "=================================================================\n",
            "Total params: 1,384,160\n",
            "Trainable params: 1,384,160\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI-HMgogsXch"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x) \n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qVmEOjjtg_4"
      },
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ttCfekEtkZi",
        "outputId": "53ad8492-9396-408b-b1e9-d4e74de11707"
      },
      "source": [
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M97p__GytmXY",
        "outputId": "df09c978-3048-43a1-ce6a-9a654e2e1c15"
      },
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20210911-173515\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 15ms/step - loss: 0.1632 - accuracy: 0.9349 - val_loss: 0.8848 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0829 - accuracy: 0.9693 - val_loss: 0.8627 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0733 - accuracy: 0.9720 - val_loss: 1.1284 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0631 - accuracy: 0.9746 - val_loss: 0.9815 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0544 - accuracy: 0.9777 - val_loss: 0.9994 - val_accuracy: 0.7677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZGTN_dttp_-",
        "outputId": "f5d77866-b8dd-41ab-c9f3-7da8a04c0ab4"
      },
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[2.18530111e-02],\n",
              "        [8.05039167e-01],\n",
              "        [9.99637127e-01],\n",
              "        [4.92835306e-02],\n",
              "        [1.18385295e-04],\n",
              "        [9.98555958e-01],\n",
              "        [7.39506543e-01],\n",
              "        [9.99873757e-01],\n",
              "        [9.99724567e-01],\n",
              "        [8.10471356e-01]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrk_7HVrtsik",
        "outputId": "6fdf4e3e-03e9-44f6-9aeb-715a66f70775"
      },
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzY7ohFftvgZ",
        "outputId": "a1bd2d50-6299-4a70-dbea-43f3e3e15804"
      },
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'f1': 0.7660466459325422,\n",
              " 'precision': 0.768489862704666,\n",
              " 'recall': 0.7677165354330708}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5wyWuc9txei",
        "outputId": "76758d4a-e48d-453f-f005-40df774f2565"
      },
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKc1E9kptzml"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you'd read an English sentence) however, a bidirectional RNN goes from right to left and then left to right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clPur84Rvmrx"
      },
      "source": [
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo-1ZnDiwHbj",
        "outputId": "9d5c548b-308b-4695-8343-b1e4f241b716"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3h3w4LxwU5Z"
      },
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S6QSsgKwL2f",
        "outputId": "1ae9bdde-fc63-4913-e863-64568193b5d5"
      },
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20210911-173540\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 22ms/step - loss: 0.1047 - accuracy: 0.9683 - val_loss: 0.9023 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0555 - accuracy: 0.9762 - val_loss: 1.1813 - val_accuracy: 0.7717\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0471 - accuracy: 0.9793 - val_loss: 1.2853 - val_accuracy: 0.7651\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0424 - accuracy: 0.9806 - val_loss: 1.4854 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0390 - accuracy: 0.9809 - val_loss: 1.2882 - val_accuracy: 0.7638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTVbRk_pwQy2",
        "outputId": "c40d987b-6ce4-459d-c5bb-6098d2b9599f"
      },
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6242123e-01],\n",
              "       [4.9429074e-01],\n",
              "       [9.9986494e-01],\n",
              "       [2.7092355e-01],\n",
              "       [9.7317625e-06],\n",
              "       [9.9823511e-01],\n",
              "       [9.0722620e-01],\n",
              "       [9.9996924e-01],\n",
              "       [9.9990118e-01],\n",
              "       [9.5124269e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvIUEHydylVb",
        "outputId": "9fde8c9f-3983-4a72-e28c-5b2c6f5a229b"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tVlKVExyn8r",
        "outputId": "d7b11255-f507-4830-e8e0-638e48354fb3"
      },
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.37795275590551,\n",
              " 'f1': 0.7621412379223811,\n",
              " 'precision': 0.764383846466808,\n",
              " 'recall': 0.7637795275590551}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIUsLC6_yqQI",
        "outputId": "ff10856e-dfb4-4b1f-df19-d2d780f62cb7"
      },
      "source": [
        "\n",
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.38, Difference: -2.89\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X63uRIJ-ysBW"
      },
      "source": [
        "### Model 5: Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z7FfNU47TN9",
        "outputId": "3f144f1d-00b7-4336-f5a4-e6aeac8d747d"
      },
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D() \n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WETHFOPT7Uwr",
        "outputId": "7da43d51-0e94-44ec-c527-0cfe55dc0595"
      },
      "source": [
        "# See the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[-0.04295464, -0.07922305, -0.00141772, ...,  0.06309047,\n",
              "           0.01911005, -0.03969366],\n",
              "         [-0.00615895, -0.01854176,  0.0359186 , ...,  0.02487346,\n",
              "          -0.01062937, -0.0153396 ],\n",
              "         [-0.00706388, -0.05419252, -0.04991948, ...,  0.03339707,\n",
              "           0.00937139,  0.00433444],\n",
              "         ...,\n",
              "         [-0.03707583, -0.03461448,  0.02817286, ...,  0.00554966,\n",
              "           0.02717419,  0.03391589],\n",
              "         [-0.03707583, -0.03461448,  0.02817286, ...,  0.00554966,\n",
              "           0.02717419,  0.03391589],\n",
              "         [-0.03707583, -0.03461448,  0.02817286, ...,  0.00554966,\n",
              "           0.02717419,  0.03391589]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[0.07754969, 0.11555281, 0.05015389, 0.04523728, 0.        ,\n",
              "          0.1217972 , 0.        , 0.        , 0.07092075, 0.04234728,\n",
              "          0.        , 0.0023914 , 0.        , 0.        , 0.        ,\n",
              "          0.03266478, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.01330865, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.00744592, 0.02325098, 0.12660348, 0.        , 0.00579443,\n",
              "          0.        , 0.00014326],\n",
              "         [0.        , 0.        , 0.        , 0.05074021, 0.04029769,\n",
              "          0.        , 0.00515421, 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.09266854, 0.        , 0.00327223, 0.        ,\n",
              "          0.02657258, 0.        , 0.        , 0.07097745, 0.        ,\n",
              "          0.00441179, 0.01322453, 0.03341659, 0.        , 0.01360613,\n",
              "          0.01943293, 0.        , 0.        , 0.0747098 , 0.        ,\n",
              "          0.        , 0.04743263],\n",
              "         [0.04543883, 0.03131794, 0.04052006, 0.05673943, 0.        ,\n",
              "          0.0357774 , 0.00146094, 0.03245282, 0.02677375, 0.08533525,\n",
              "          0.        , 0.        , 0.00570978, 0.02177316, 0.        ,\n",
              "          0.        , 0.05864366, 0.        , 0.0332697 , 0.11340532,\n",
              "          0.08933552, 0.02390945, 0.        , 0.        , 0.        ,\n",
              "          0.0124479 , 0.00481588, 0.        , 0.08004561, 0.        ,\n",
              "          0.        , 0.04505306],\n",
              "         [0.05225485, 0.0175208 , 0.        , 0.        , 0.00869846,\n",
              "          0.04222184, 0.        , 0.        , 0.        , 0.02179457,\n",
              "          0.        , 0.00297632, 0.01223371, 0.        , 0.01386513,\n",
              "          0.00334448, 0.        , 0.        , 0.00858347, 0.02839638,\n",
              "          0.05455075, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.03878547, 0.        , 0.06078655, 0.01028375,\n",
              "          0.01028547, 0.09558284],\n",
              "         [0.06888708, 0.00567797, 0.0020977 , 0.03647717, 0.02970142,\n",
              "          0.02191656, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.03953096, 0.        , 0.0174813 ,\n",
              "          0.        , 0.02019466, 0.        , 0.01502077, 0.03070374,\n",
              "          0.00499246, 0.01677511, 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.03809219, 0.        , 0.02196745, 0.        ,\n",
              "          0.04314899, 0.02809505],\n",
              "         [0.06103485, 0.03556872, 0.00938312, 0.07684362, 0.03519838,\n",
              "          0.02247748, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.02381257, 0.05615036, 0.        , 0.        ,\n",
              "          0.00028934, 0.        , 0.02415858, 0.        , 0.03983176,\n",
              "          0.01483519, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.00797964, 0.01557925, 0.00538811, 0.        ,\n",
              "          0.        , 0.03406417],\n",
              "         [0.06103485, 0.03556872, 0.00938312, 0.07684363, 0.03519838,\n",
              "          0.02247747, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.02381258, 0.05615037, 0.        , 0.        ,\n",
              "          0.00028934, 0.        , 0.02415859, 0.        , 0.03983177,\n",
              "          0.01483518, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.00797964, 0.01557925, 0.0053881 , 0.        ,\n",
              "          0.        , 0.03406417],\n",
              "         [0.06103486, 0.03556872, 0.00938312, 0.07684363, 0.03519839,\n",
              "          0.02247748, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.02381256, 0.05615037, 0.        , 0.        ,\n",
              "          0.00028933, 0.        , 0.02415859, 0.        , 0.03983176,\n",
              "          0.01483519, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.00797964, 0.01557926, 0.0053881 , 0.        ,\n",
              "          0.        , 0.03406417],\n",
              "         [0.06103485, 0.03556873, 0.00938313, 0.07684363, 0.03519838,\n",
              "          0.02247749, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.02381257, 0.05615036, 0.        , 0.        ,\n",
              "          0.00028934, 0.        , 0.02415859, 0.        , 0.03983176,\n",
              "          0.01483519, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.00797963, 0.01557926, 0.0053881 , 0.        ,\n",
              "          0.        , 0.03406417],\n",
              "         [0.06103485, 0.03556872, 0.00938312, 0.07684363, 0.03519839,\n",
              "          0.02247748, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.02381258, 0.05615036, 0.        , 0.        ,\n",
              "          0.00028934, 0.        , 0.02415858, 0.        , 0.03983176,\n",
              "          0.01483519, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.00797964, 0.01557925, 0.0053881 , 0.        ,\n",
              "          0.        , 0.03406417],\n",
              "         [0.06103485, 0.03556872, 0.00938312, 0.07684363, 0.03519839,\n",
              "          0.02247748, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.02381257, 0.05615037, 0.        , 0.        ,\n",
              "          0.00028933, 0.        , 0.02415859, 0.        , 0.03983176,\n",
              "          0.01483519, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.00797964, 0.01557925, 0.0053881 , 0.        ,\n",
              "          0.        , 0.03406417]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.07754969, 0.11555281, 0.05015389, 0.07684363, 0.04029769,\n",
              "         0.1217972 , 0.00515421, 0.03245282, 0.07092075, 0.08533525,\n",
              "         0.        , 0.09266854, 0.05615037, 0.02177316, 0.0174813 ,\n",
              "         0.03266478, 0.05864366, 0.02415859, 0.07097745, 0.11340532,\n",
              "         0.08933552, 0.02390945, 0.03341659, 0.        , 0.01360613,\n",
              "         0.01943293, 0.03878547, 0.12660348, 0.08004561, 0.01028375,\n",
              "         0.04314899, 0.09558284]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLjJzx4Y7Wbh",
        "outputId": "cb98254c-fb94-44ed-ea6a-7e67363e0485"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "model_5.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 32)            20512     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSUguEwG7Y9q",
        "outputId": "5fe0d485-5864-4416-9d37-27218fdedb69"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210911-173624\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 11ms/step - loss: 0.1388 - accuracy: 0.9555 - val_loss: 0.8444 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0779 - accuracy: 0.9699 - val_loss: 0.9860 - val_accuracy: 0.7559\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0626 - accuracy: 0.9768 - val_loss: 1.0982 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0557 - accuracy: 0.9778 - val_loss: 1.1223 - val_accuracy: 0.7585\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0503 - accuracy: 0.9787 - val_loss: 1.1703 - val_accuracy: 0.7598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ueF2YdP7a8T",
        "outputId": "9642979c-779a-48fd-b663-3b581b06ed2e"
      },
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.4978055e-01],\n",
              "       [9.6126348e-01],\n",
              "       [9.9986434e-01],\n",
              "       [5.7888720e-02],\n",
              "       [2.1863620e-07],\n",
              "       [9.9660337e-01],\n",
              "       [9.9040866e-01],\n",
              "       [9.9999571e-01],\n",
              "       [9.9999976e-01],\n",
              "       [9.3614376e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDxr09-Y7cOb",
        "outputId": "db29b6b9-e8c5-4a23-bb18-e02bab7197ea"
      },
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1cNn2aa7eIW",
        "outputId": "1e4ce04a-7cd9-4d0e-8900-fc8a860a647e"
      },
      "source": [
        "\n",
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'f1': 0.7589841599505696,\n",
              " 'precision': 0.7595269214829928,\n",
              " 'recall': 0.7598425196850394}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvYJ1uFs7fhW",
        "outputId": "91d35d62-0752-401b-febf-f990cc97cde1"
      },
      "source": [
        "# Compare model_5 results to baseline \n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.98, Difference: -3.28\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxL7z0pJ7g7X"
      },
      "source": [
        "### Model 6: Tensorflow Hub Pretrained Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-tcRdZn9EtW",
        "outputId": "3a5b616d-b29d-4b2f-8ff2-8c9625578b0b"
      },
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157024  0.0248591   0.0287805  -0.01271502  0.03971543  0.08827759\n",
            "  0.02680986  0.05589837 -0.01068731 -0.0059729   0.00639324 -0.01819523\n",
            "  0.00030817  0.09105891  0.05874644 -0.03180627  0.01512476 -0.05162928\n",
            "  0.00991369 -0.06865346 -0.04209306  0.0267898   0.03011008  0.00321069\n",
            " -0.00337969 -0.04787359  0.02266718 -0.00985924 -0.04063614 -0.01292095\n",
            " -0.04666384  0.056303   -0.03949255  0.00517685  0.02495828 -0.07014439\n",
            "  0.02871508  0.04947682 -0.00633971 -0.08960191  0.02807117 -0.00808362\n",
            " -0.01360601  0.05998649 -0.10361786 -0.05195372  0.00232955 -0.02332528\n",
            " -0.03758105  0.0332773 ], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLRNmXX19GQt",
        "outputId": "32616204-f51f-4fa3-9dda-ce94aa6fdc25"
      },
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl9PtGmN9HrI"
      },
      "source": [
        "\n",
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYbd7n-A9J32",
        "outputId": "5b8dcf09-9757-4c30-9570-929b22990109"
      },
      "source": [
        "\n",
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFlyKc0h9LnA",
        "outputId": "c2e29801-bf9b-45a6-9890-a36904d0f4f0"
      },
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210911-174322\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 33ms/step - loss: 0.5066 - accuracy: 0.7879 - val_loss: 0.4495 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.4147 - accuracy: 0.8159 - val_loss: 0.4381 - val_accuracy: 0.8084\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.4021 - accuracy: 0.8228 - val_loss: 0.4347 - val_accuracy: 0.8071\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3941 - accuracy: 0.8235 - val_loss: 0.4299 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3869 - accuracy: 0.8298 - val_loss: 0.4300 - val_accuracy: 0.8097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5xfZU249Ofa",
        "outputId": "232d96b3-7ad7-4da9-c058-fe2f7904d9f1"
      },
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16365956],\n",
              "       [0.77393377],\n",
              "       [0.9887193 ],\n",
              "       [0.21503244],\n",
              "       [0.7107343 ],\n",
              "       [0.745682  ],\n",
              "       [0.9765603 ],\n",
              "       [0.9767892 ],\n",
              "       [0.94438493],\n",
              "       [0.10920196]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijEalMU99P-a",
        "outputId": "31df1c54-a7cb-465b-bad0-1c17f2de2ab2"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQSLh2gc9Ru8",
        "outputId": "bc588de3-9c3c-456d-898c-5d2991fac71f"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.97112860892388,\n",
              " 'f1': 0.8081431756423573,\n",
              " 'precision': 0.8118825131433668,\n",
              " 'recall': 0.8097112860892388}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K17859hX9TJB",
        "outputId": "0217758b-de59-4d9f-abd7-f447652e21ca"
      },
      "source": [
        "# Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 80.97, Difference: 1.71\n",
            "Baseline precision: 0.81, New precision: 0.81, Difference: 0.00\n",
            "Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n",
            "Baseline f1: 0.79, New f1: 0.81, Difference: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8fnJPOc9Utp"
      },
      "source": [
        "### Model 7: TensorFlow Hub Pretrained Sentence Encoder 10% of the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3PEEKr8AjJi"
      },
      "source": [
        "### NOTE: Making splits like this will lead to data leakage ###\n",
        "### (some of the training examples in the validation set) ###\n",
        "\n",
        "### WRONG WAY TO MAKE SPLITS (train_df_shuffled has already been split) ### \n",
        "\n",
        "# # Create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttnmxJ5vAmGB"
      },
      "source": [
        "\n",
        "# One kind of correct way (there are more) to make data subset\n",
        "# (split the already split train_sentences/train_labels)\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=42)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfzQbVovAnNh",
        "outputId": "a9dd9cbf-18a4-4c54-a600-9c3f287eea2f"
      },
      "source": [
        "\n",
        "# Check length of 10 percent datasets\n",
        "print(f\"Total training examples: {len(train_sentences)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEDVNJB7Aosk",
        "outputId": "1928ad98-47bb-4866-e94f-90e1509bcfd5"
      },
      "source": [
        "# Check the number of targets in our subset of data \n",
        "# (this should be close to the distribution of labels in the original train_labels)\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415\n",
              "1    271\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TCl29AMAqhD",
        "outputId": "480cbbaf-cb6b-4910-e64b-affd1976e4bb"
      },
      "source": [
        "\n",
        "# Clone model_6 but reset weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL2EYkYVAr1f",
        "outputId": "797c073f-1be8-4d7e-c081-ad2a4b78a9db"
      },
      "source": [
        "# Fit the model to 10% of the training data\n",
        "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20210911-175840\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 6s 149ms/step - loss: 0.6704 - accuracy: 0.6808 - val_loss: 0.6478 - val_accuracy: 0.7270\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.5940 - accuracy: 0.8090 - val_loss: 0.5878 - val_accuracy: 0.7507\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.5141 - accuracy: 0.8222 - val_loss: 0.5293 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 50ms/step - loss: 0.4488 - accuracy: 0.8280 - val_loss: 0.5016 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.4052 - accuracy: 0.8324 - val_loss: 0.4868 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDp1ZDC5Auqn",
        "outputId": "da2f9fc3-e05c-4b1c-fabf-fe8b9308417a"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.28014734],\n",
              "       [0.78759825],\n",
              "       [0.91473943],\n",
              "       [0.31331077],\n",
              "       [0.5389464 ],\n",
              "       [0.8502201 ],\n",
              "       [0.82950115],\n",
              "       [0.8693915 ],\n",
              "       [0.84499204],\n",
              "       [0.12743546]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzkW1k7ZAw0U",
        "outputId": "808e93a5-0fbb-43a3-cbe7-42150cf38212"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh4l2kxeAy1a",
        "outputId": "321e5591-7d69-4dd6-f957-32e528fed395"
      },
      "source": [
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'f1': 0.7748637513129987,\n",
              " 'precision': 0.7833771178803304,\n",
              " 'recall': 0.7782152230971129}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ll-ZNX_A0QC",
        "outputId": "cb2c1b7a-f1e5-4c36-9bad-75f183d10a8d"
      },
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.82, Difference: -1.44\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBrN_jmxA1mD"
      },
      "source": [
        "### Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "KxE_669pA3qM",
        "outputId": "579b3812-cc5e-4206-be64-86945b2cdd7b"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>78.477690</td>\n",
              "      <td>0.789165</td>\n",
              "      <td>0.784777</td>\n",
              "      <td>0.781896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>77.034121</td>\n",
              "      <td>0.772347</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.768060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>76.771654</td>\n",
              "      <td>0.768490</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.377953</td>\n",
              "      <td>0.764384</td>\n",
              "      <td>0.763780</td>\n",
              "      <td>0.762141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>75.984252</td>\n",
              "      <td>0.759527</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>80.971129</td>\n",
              "      <td>0.811883</td>\n",
              "      <td>0.809711</td>\n",
              "      <td>0.808143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.783377</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.774864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 79.265092   0.811139  0.792651  0.786219\n",
              "simple_dense             78.477690   0.789165  0.784777  0.781896\n",
              "lstm                     77.034121   0.772347  0.770341  0.768060\n",
              "gru                      76.771654   0.768490  0.767717  0.766047\n",
              "bidirectional            76.377953   0.764384  0.763780  0.762141\n",
              "conv1d                   75.984252   0.759527  0.759843  0.758984\n",
              "tf_hub_sentence_encoder  80.971129   0.811883  0.809711  0.808143\n",
              "tf_hub_10_percent_data   77.821522   0.783377  0.778215  0.774864"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqYm7n_6A5d6"
      },
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "Ul6JlHZsA7st",
        "outputId": "f07eeae9-e4b0-4e35-e5d2-e9325dfd66ff"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "PQ1wV6dTA9NB",
        "outputId": "d8c77d91-66df-4719-92c2-594328d6bf8f"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07nQn0BCA-vE"
      },
      "source": [
        "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "# # Upload TensorBoard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs \\\n",
        "#   --name \"NLP modelling experiments\" \\\n",
        "#   --description \"A series of different NLP modellings experiments with various models\" \\\n",
        "#   --one_shot # exits the uploader when upload has finished"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzj5eRT5BAsp"
      },
      "source": [
        "# If you need to remove previous experiments, you can do so using the following command\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOpuP2-gBCLp"
      },
      "source": [
        "### Combining our models (model ensembling/stacking)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEq2_RSwBGUN",
        "outputId": "b0f6d821-e46f-4280-a15c-7fbda3aecb23"
      },
      "source": [
        "# Get mean pred probs for 3 models\n",
        "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
        "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
        "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
        "combined_preds[:20]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSaXdXl1BH9F",
        "outputId": "0e653a75-d45a-4ce6-91a4-827250d1c939"
      },
      "source": [
        "# Calculate results from averaging the prediction probabilities\n",
        "ensemble_results = calculate_results(val_labels, combined_preds)\n",
        "ensemble_results"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.65879265091863,\n",
              " 'f1': 0.7962881430926292,\n",
              " 'precision': 0.7963229487220014,\n",
              " 'recall': 0.7965879265091863}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF_LBNf-BJjN"
      },
      "source": [
        "# Add our combined model's results to the results DataFrame\n",
        "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw2vAKI9BLEG"
      },
      "source": [
        "# Convert the accuracy to the same scale as the rest of the results\n",
        "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "kFsokAQaBMs9",
        "outputId": "ef4d597f-93a8-40ac-ab9c-588cedf92ab8"
      },
      "source": [
        "all_model_results\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.784777</td>\n",
              "      <td>0.789165</td>\n",
              "      <td>0.784777</td>\n",
              "      <td>0.781896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.772347</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.768060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.768490</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.763780</td>\n",
              "      <td>0.764384</td>\n",
              "      <td>0.763780</td>\n",
              "      <td>0.762141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.759527</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.758984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.809711</td>\n",
              "      <td>0.811883</td>\n",
              "      <td>0.809711</td>\n",
              "      <td>0.808143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.783377</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.774864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>0.796588</td>\n",
              "      <td>0.796323</td>\n",
              "      <td>0.796588</td>\n",
              "      <td>0.796288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                 0.792651   0.811139  0.792651  0.786219\n",
              "simple_dense             0.784777   0.789165  0.784777  0.781896\n",
              "lstm                     0.770341   0.772347  0.770341  0.768060\n",
              "gru                      0.767717   0.768490  0.767717  0.766047\n",
              "bidirectional            0.763780   0.764384  0.763780  0.762141\n",
              "conv1d                   0.759843   0.759527  0.759843  0.758984\n",
              "tf_hub_sentence_encoder  0.809711   0.811883  0.809711  0.808143\n",
              "tf_hub_10_percent_data   0.778215   0.783377  0.778215  0.774864\n",
              "ensemble_results         0.796588   0.796323  0.796588  0.796288"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkQJYJfLBNt3"
      },
      "source": [
        "### Saving and loading a trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTITKAtoBS5a"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEOOX9k7BUIu"
      },
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn8ryBdKBWH_",
        "outputId": "271116d0-c88c-43c0-a841-56697c848a69"
      },
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 17ms/step - loss: 0.4300 - accuracy: 0.8097\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4299670159816742, 0.8097112774848938]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jo7nOecBYCr",
        "outputId": "90b9a678-5ea6-47f5-87b6-15ac2903bf22"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUfw60_nBZo5"
      },
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yG62cDBBbUa",
        "outputId": "f0578598-11b4-4345-d6d4-4701955d7a61"
      },
      "source": [
        "\n",
        "# Evaluate loaded SavedModel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 18ms/step - loss: 0.4300 - accuracy: 0.8097\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4299669563770294, 0.8097112774848938]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGCVjajMBdJQ"
      },
      "source": [
        "### Finding the most wrong examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2hCpr88aBiqn",
        "outputId": "7f55d061-4a3a-4a30-be48-7e1ba380a423"
      },
      "source": [
        "\n",
        "# Create dataframe with validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.163660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.773934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.215032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.710734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.163660\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.773934\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988719\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.215032\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.710734"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ZQwCqZCKBi7S",
        "outputId": "87e7b47e-a226-4211-b26e-72bf88a08f79"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.915115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.885450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.872673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.864359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.836204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>Deaths 3 http://t.co/nApviyGKYK</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.816379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.815652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.809360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.790081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.915115\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.885450\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.872673\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.864359\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.836204\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.827738\n",
              "381                    Deaths 3 http://t.co/nApviyGKYK       0   1.0   0.816379\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.815652\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.809360\n",
              "698  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       0   1.0   0.790081"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46luj4_ZBkMv",
        "outputId": "7551e741-16b7-4c03-8e09-40365cbab3b0"
      },
      "source": [
        "\n",
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.915115475654602\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8854497075080872\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8726726770401001\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8643589615821838\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8362041711807251\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8277379870414734\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8163789510726929\n",
            "Text:\n",
            "Deaths 3 http://t.co/nApviyGKYK\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8156515955924988\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8093603253364563\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.7900806069374084\n",
            "Text:\n",
            "åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgld1nnyBlpM",
        "outputId": "55b8486e-28ab-46df-9b31-3abdf4db283b"
      },
      "source": [
        "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.05802590399980545\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.05772469937801361\n",
            "Text:\n",
            "'The way you move is like a full on rainstorm and I'm a house of cards'\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.053100474178791046\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.049916964024305344\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.04905632883310318\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.047832705080509186\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.04149486869573593\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03874434530735016\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.03264029696583748\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.028745340183377266\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEoLPwsEBoIp"
      },
      "source": [
        "### Making predictions on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XlRZvsUBrXG",
        "outputId": "d10b447d-1300-48a1-cde2-e42c8fc30f6e"
      },
      "source": [
        "# Making predictions on the test dataset\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0, Prob: 0.12759782373905182\n",
            "Text:\n",
            "Pissed something off in the wood pile. Pulling pieces out and I get a small hiss and a series of low clicks for my trouble.\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.9826521873474121\n",
            "Text:\n",
            "@Ramdog1980 Israeli soldiers demolished a residential shed and a barn. Soldiers also demolished a shed in Beit Kahel northwest of Hebron.\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.9670974612236023\n",
            "Text:\n",
            "http://t.co/Dg0EcBYKJL Tornado warnings end after thunderstorms hammer Calgary region for 2nd night #HeadlinesApp\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.7954830527305603\n",
            "Text:\n",
            "@Musketeiro I see ISIL destroyed in Iraq in  May 2016. This may help Iraqis help Syrian government against it. But Nusrah and Ahrar not yet.\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.7565541863441467\n",
            "Text:\n",
            "Family heartbroken.Mobile home at Nellis &amp; Cheyenne burned in fire. Kids were all ready to go back 2 school @News3LV http://t.co/VAf1RAiYQb\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.07847338914871216\n",
            "Text:\n",
            "Politicians are using false allegations to attack #PlannedParenthood &amp; harm women. We aren't fooled we #StandwithPP http://t.co/JhseGQLbYq\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.8979789614677429\n",
            "Text:\n",
            "Trying to route my sister into W. Lafayette from the Indy airport. Suggested I-74 to SR 25 west of Crawfordsville. Hope it's not a disaster.\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.08856634050607681\n",
            "Text:\n",
            "@usetheIight youre an ugly piece of trash i hope u fall off a cliff\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.21187710762023926\n",
            "Text:\n",
            "We all knew Cain wasn't going to die... It's either Val or someone is gonna collapse later on... #Emmerdale #SummerFate\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.4664789140224457\n",
            "Text:\n",
            "These women all bonded through tragedy. All of em were broken in some way\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvlpmfUUBt9p"
      },
      "source": [
        "### Predicting on Tweets from the wild"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0557SWeBw9V"
      },
      "source": [
        "# Turn Tweet into string\n",
        "daniels_tweet = \"Life like an ensemble: take the best choices from others and make your own\""
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7JuFBvOBzc0"
      },
      "source": [
        "\n",
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  Uses model to make a prediction on sentence.\n",
        "\n",
        "  Returns the sentence, the predicted label and the prediction probability.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eCJTAJ3B1Rw",
        "outputId": "cc75e068-2845-4d1d-8aa4-391a1c901f70"
      },
      "source": [
        "# Make a prediction on Tweet from the wild\n",
        "predict_on_sentence(model=model_6, # use the USE model\n",
        "                    sentence=daniels_tweet)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0.0 (not real disaster) Prob: 0.05400461703538895\n",
            "Text:\n",
            "Life like an ensemble: take the best choices from others and make your own\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQDrRtETB3lR"
      },
      "source": [
        "#Source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
        "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
        "\n",
        "# Source - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
        "beirut_tweet_2 = \"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\""
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrfKDNucB5aB",
        "outputId": "2ae33ed8-8344-4775-fee0-2c5d9fab7558"
      },
      "source": [
        "# Predict on diaster Tweet 1\n",
        "predict_on_sentence(model=model_6, \n",
        "                    sentence=beirut_tweet_1)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9615726470947266\n",
            "Text:\n",
            "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZLIx9_lB-Av",
        "outputId": "209f926e-40fb-4d1e-b9a3-703f6adc5407"
      },
      "source": [
        "# Predict on diaster Tweet 2\n",
        "predict_on_sentence(model=model_6, \n",
        "                    sentence=beirut_tweet_2)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9750996828079224\n",
            "Text:\n",
            "#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9IE1n05B_t3"
      },
      "source": [
        "### The speed/score tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5dmBc5uCCV3"
      },
      "source": [
        "# Calculate the time of predictions\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \n",
        "  Args:\n",
        "  ----\n",
        "  model = a trained model\n",
        "  sample = a list of samples\n",
        "\n",
        "  Returns:\n",
        "  ----\n",
        "  total_time = total elapsed time for model to make predictions on samples\n",
        "  time_per_pred = time in seconds per single sample\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time-start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(val_sentences) # find prediction time per sample\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF5RKFOwCEZK",
        "outputId": "8c716c9d-adfa-48ed-8f69-913f721a0632"
      },
      "source": [
        "# Calculate TF Hub Sentence Encoder prediction times\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.41911929699926986, 0.0005500253241460235)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEK_m6IeCGDK",
        "outputId": "3a806fae-9822-48fb-8c0c-7bbbc13d566c"
      },
      "source": [
        "# Calculate Naive Bayes prediction times\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.024088647000098717, 3.161239763792483e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ypBRtM5xCHnl",
        "outputId": "a54c772b-13e9-488c-ad8f-15260afd432d"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\");"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuW2wCjmCJDs"
      },
      "source": [
        "# THE END"
      ]
    }
  ]
}